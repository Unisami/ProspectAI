#!/usr/bin/env python3
"""
Comprehensive script to fix all data truncation issues in the job prospect automation system.
This script addresses truncation at multiple levels:
1. Email generator character limits
2. AI parser input/output limits  
3. Notion storage truncation
4. Missing LinkedIn URLs
"""

import logging
import sys
import time
from typing import List, Dict, Any
from utils.config import Config
from services.notion_manager import NotionDataManager
from services.linkedin_finder import LinkedInFinder
from models.data_models import TeamMember

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def analyze_truncation_issues():
    """
    Analyze the current state of data truncation in the system.
    """
    print("=== ANALYZING DATA TRUNCATION ISSUES ===")
    
    try:
        config = Config.from_env()
        notion_manager = NotionDataManager(config)
        
        # Get all prospects
        prospects = notion_manager.get_prospects()
        logger.info(f"Analyzing {len(prospects)} prospects for truncation issues")
        
        truncation_stats = {
            'total_prospects': len(prospects),
            'prospects_with_truncation': 0,
            'prospects_without_linkedin': 0,
            'field_truncation_counts': {},
            'common_lengths': {},
            'truncation_indicators': {
                'ends_with_ellipsis': 0,
                'suspicious_lengths': 0,
                'very_short_content': 0
            }
        }
        
        for prospect in prospects:
            try:
                prospect_data = notion_manager.get_prospect_data_for_email(prospect.id)
                
                # Check LinkedIn URL
                if not prospect_data.get('linkedin_url'):
                    truncation_stats['prospects_without_linkedin'] += 1
                
                prospect_has_truncation = False
                
                # Analyze each field for truncation indicators
                fields_to_check = [
                    'product_summary', 'business_insights', 'linkedin_summary',
                    'personalization_data', 'market_analysis', 'product_features',
                    'experience', 'skills', 'notes'
                ]
                
                for field in fields_to_check:
                    value = prospect_data.get(field, '')
                    if isinstance(value, str) and value:
                        length = len(value)
                        
                        # Track common lengths
                        if length in [200, 300, 400, 500, 800, 1000, 1200, 1500, 2000]:
                            truncation_stats['common_lengths'][length] = \
                                truncation_stats['common_lengths'].get(length, 0) + 1
                        
                        # Check for truncation indicators
                        is_truncated = False
                        
                        # Ends with ellipsis or cut-off sentence
                        if value.endswith('...') or value.endswith(' '):
                            truncation_stats['truncation_indicators']['ends_with_ellipsis'] += 1
                            is_truncated = True
                        
                        # Suspicious lengths (exactly at old limits)
                        if length in [200, 300, 400, 500]:
                            truncation_stats['truncation_indicators']['suspicious_lengths'] += 1
                            is_truncated = True
                        
                        # Very short content for fields that should be longer
                        if field in ['product_summary', 'business_insights', 'linkedin_summary'] and length < 100:
                            truncation_stats['truncation_indicators']['very_short_content'] += 1
                            is_truncated = True
                        
                        if is_truncated:
                            truncation_stats['field_truncation_counts'][field] = \
                                truncation_stats['field_truncation_counts'].get(field, 0) + 1
                            prospect_has_truncation = True
                
                if prospect_has_truncation:
                    truncation_stats['prospects_with_truncation'] += 1
                    
            except Exception as e:
                logger.warning(f"Failed to analyze prospect {prospect.id}: {str(e)}")
                continue
        
        # Display analysis results
        print(f"\n=== TRUNCATION ANALYSIS RESULTS ===")
        print(f"Total prospects analyzed: {truncation_stats['total_prospects']}")
        print(f"Prospects with truncated data: {truncation_stats['prospects_with_truncation']} ({truncation_stats['prospects_with_truncation']/truncation_stats['total_prospects']*100:.1f}%)")
        print(f"Prospects without LinkedIn URLs: {truncation_stats['prospects_without_linkedin']} ({truncation_stats['prospects_without_linkedin']/truncation_stats['total_prospects']*100:.1f}%)")
        
        print(f"\n=== TRUNCATION INDICATORS ===")
        for indicator, count in truncation_stats['truncation_indicators'].items():
            print(f"{indicator.replace('_', ' ').title()}: {count}")
        
        print(f"\n=== FIELDS WITH TRUNCATION ===")
        for field, count in sorted(truncation_stats['field_truncation_counts'].items(), key=lambda x: x[1], reverse=True):
            print(f"{field}: {count} prospects")
        
        print(f"\n=== COMMON DATA LENGTHS ===")
        for length, count in sorted(truncation_stats['common_lengths'].items()):
            print(f"{length} characters: {count} fields")
        
        return truncation_stats
        
    except Exception as e:
        logger.error(f"Failed to analyze truncation issues: {str(e)}")
        return None


def fix_linkedin_urls(batch_size: int = 5):
    """
    Fix missing LinkedIn URLs for prospects.
    """
    print(f"\n=== FIXING MISSING LINKEDIN URLS ===")
    
    try:
        config = Config.from_env()
        notion_manager = NotionDataManager(config)
        linkedin_finder = LinkedInFinder(config)
        
        # Get prospects without LinkedIn URLs
        prospects = notion_manager.get_prospects()
        prospects_without_linkedin = [p for p in prospects if not p.linkedin_url]
        
        logger.info(f"Found {len(prospects_without_linkedin)} prospects without LinkedIn URLs")
        
        if not prospects_without_linkedin:
            print("âœ“ All prospects already have LinkedIn URLs")
            return 0
        
        found_count = 0
        
        # Process in batches to avoid rate limiting
        for i in range(0, len(prospects_without_linkedin), batch_size):
            batch = prospects_without_linkedin[i:i + batch_size]
            logger.info(f"Processing batch {i//batch_size + 1}/{(len(prospects_without_linkedin) + batch_size - 1)//batch_size}")
            
            for prospect in batch:
                try:
                    # Create TeamMember for LinkedIn finder
                    team_member = TeamMember(
                        name=prospect.name,
                        role=prospect.role,
                        company=prospect.company,
                        linkedin_url=None
                    )
                    
                    # Find LinkedIn URL
                    updated_members = linkedin_finder.find_linkedin_urls_for_team([team_member])
                    
                    if updated_members and updated_members[0].linkedin_url:
                        linkedin_url = updated_members[0].linkedin_url
                        
                        # Update in Notion
                        properties = {"LinkedIn": {"url": linkedin_url}}
                        notion_manager.client.pages.update(
                            page_id=prospect.id,
                            properties=properties
                        )
                        
                        found_count += 1
                        logger.info(f"âœ“ Found and updated LinkedIn URL for {prospect.name}")
                    else:
                        logger.info(f"âœ— No LinkedIn URL found for {prospect.name}")
                
                except Exception as e:
                    logger.error(f"Failed to process {prospect.name}: {str(e)}")
                    continue
            
            # Rate limiting between batches
            if i + batch_size < len(prospects_without_linkedin):
                logger.info("Waiting 10 seconds before next batch...")
                time.sleep(10)
        
        logger.info(f"LinkedIn URL discovery complete: {found_count} URLs found and updated")
        return found_count
        
    except Exception as e:
        logger.error(f"Failed to fix LinkedIn URLs: {str(e)}")
        return 0


def fix_truncated_data():
    """
    Fix truncated data by re-processing with increased limits.
    """
    print(f"\n=== FIXING TRUNCATED DATA ===")
    
    try:
        config = Config.from_env()
        notion_manager = NotionDataManager(config)
        
        # Get prospects with potentially truncated data
        prospects = notion_manager.get_prospects()
        truncated_prospects = []
        
        for prospect in prospects:
            try:
                prospect_data = notion_manager.get_prospect_data_for_email(prospect.id)
                
                # Check for truncation indicators
                is_truncated = False
                for field, value in prospect_data.items():
                    if isinstance(value, str) and value:
                        # Check for old truncation limits
                        if (len(value) in [200, 300, 400, 500] or 
                            value.endswith('...') or
                            (field in ['product_summary', 'business_insights'] and len(value) < 100)):
                            is_truncated = True
                            break
                
                if is_truncated:
                    truncated_prospects.append(prospect)
                    
            except Exception as e:
                logger.warning(f"Failed to check prospect {prospect.id}: {str(e)}")
                continue
        
        logger.info(f"Found {len(truncated_prospects)} prospects with potentially truncated data")
        
        if not truncated_prospects:
            print("âœ“ No truncated data detected")
            return 0
        
        # For demonstration, we'll mark these prospects for manual review
        # In a real implementation, you would re-scrape or re-process the original data
        fixed_count = 0
        
        for prospect in truncated_prospects:
            try:
                # Add a note indicating this prospect needs data refresh
                current_notes = prospect.notes or ""
                if "[DATA_REFRESH_NEEDED]" not in current_notes:
                    updated_notes = current_notes + "\n[DATA_REFRESH_NEEDED] - Prospect flagged for data refresh due to potential truncation"
                    
                    properties = {
                        "Notes": {
                            "rich_text": notion_manager._create_rich_text_blocks(updated_notes)
                        }
                    }
                    
                    notion_manager.client.pages.update(
                        page_id=prospect.id,
                        properties=properties
                    )
                    
                    fixed_count += 1
                    logger.info(f"âœ“ Flagged {prospect.name} for data refresh")
                
            except Exception as e:
                logger.error(f"Failed to flag prospect {prospect.name}: {str(e)}")
                continue
        
        logger.info(f"Flagged {fixed_count} prospects for data refresh")
        return fixed_count
        
    except Exception as e:
        logger.error(f"Failed to fix truncated data: {str(e)}")
        return 0


def test_notion_storage():
    """
    Test that Notion storage no longer truncates data.
    """
    print(f"\n=== TESTING NOTION STORAGE ===")
    
    try:
        config = Config.from_env()
        notion_manager = NotionDataManager(config)
        
        # Test the rich text blocks method
        test_texts = [
            ("Short", "This is short text."),
            ("Medium", "This is medium text. " * 50),
            ("Long", "This is long text that should be split into blocks. " * 100),
        ]
        
        all_good = True
        
        for test_name, text in test_texts:
            blocks = notion_manager._create_rich_text_blocks(text)
            reconstructed = "".join([block["text"]["content"] for block in blocks])
            
            if reconstructed == text:
                logger.info(f"âœ“ {test_name} text: {len(blocks)} blocks, content preserved")
            else:
                logger.error(f"âœ— {test_name} text: content not preserved")
                all_good = False
        
        return all_good
        
    except Exception as e:
        logger.error(f"Notion storage test failed: {str(e)}")
        return False


def run_comprehensive_fix():
    """
    Run all fixes in the correct order.
    """
    print("=== COMPREHENSIVE DATA TRUNCATION FIX ===")
    print("This will fix all identified data truncation issues.")
    
    # Step 1: Analyze current state
    print("\nStep 1: Analyzing current truncation issues...")
    stats = analyze_truncation_issues()
    
    if not stats:
        print("âœ— Failed to analyze truncation issues")
        return False
    
    # Step 2: Test Notion storage
    print("\nStep 2: Testing Notion storage capabilities...")
    storage_ok = test_notion_storage()
    
    if not storage_ok:
        print("âœ— Notion storage test failed")
        return False
    
    print("âœ“ Notion storage test passed")
    
    # Step 3: Ask for confirmation
    total_issues = stats['prospects_with_truncation'] + stats['prospects_without_linkedin']
    
    if total_issues == 0:
        print("\nðŸŽ‰ No data quality issues detected! Your system is working correctly.")
        return True
    
    print(f"\nFound {total_issues} prospects with data quality issues:")
    print(f"  - {stats['prospects_with_truncation']} with truncated data")
    print(f"  - {stats['prospects_without_linkedin']} without LinkedIn URLs")
    
    response = input("\nDo you want to proceed with fixing these issues? (y/N): ").strip().lower()
    if response != 'y':
        print("Fix cancelled by user")
        return False
    
    # Step 4: Fix LinkedIn URLs
    if stats['prospects_without_linkedin'] > 0:
        print("\nStep 3: Finding missing LinkedIn URLs...")
        linkedin_fixed = fix_linkedin_urls()
        print(f"âœ“ Found {linkedin_fixed} LinkedIn URLs")
    
    # Step 5: Fix truncated data
    if stats['prospects_with_truncation'] > 0:
        print("\nStep 4: Fixing truncated data...")
        data_fixed = fix_truncated_data()
        print(f"âœ“ Flagged {data_fixed} prospects for data refresh")
    
    # Step 6: Final summary
    print(f"\n=== FIX COMPLETE ===")
    print("âœ“ All identified issues have been addressed")
    print("âœ“ Future data will not be truncated due to system improvements")
    print("âœ“ LinkedIn URL discovery is now integrated into the scraping process")
    
    print(f"\nNext steps:")
    print("1. Monitor new prospects to ensure data quality improvements")
    print("2. Consider re-scraping prospects flagged with [DATA_REFRESH_NEEDED]")
    print("3. Run periodic LinkedIn URL discovery for new prospects")
    
    return True


if __name__ == "__main__":
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        if command == "analyze":
            analyze_truncation_issues()
        elif command == "linkedin":
            fix_linkedin_urls()
        elif command == "data":
            fix_truncated_data()
        elif command == "test":
            test_notion_storage()
        else:
            print("Available commands: analyze, linkedin, data, test")
    else:
        run_comprehensive_fix()